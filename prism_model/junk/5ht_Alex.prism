dtmc

const int wait_at_reward_location = 0; //int defining boundary of area "next to" reward location, where the reward will appear.
const int l; //size of the scale representing the distance between the agent slowing down and the central reward spawn point.
const int delay; //number of steps to wait to spawn reward once agent waits at reward_location
const int MAX = 2000;
const int reward_unseen_speed; //speed of agent when vis2 = 0 
const int reward_seen_speed = 200; //speed of agent when vis2 = 1
const int speed_uncertainty;
const int reward_spread;
 


//global reward_present : bool init false; 
global in_front_of_reward_location : bool init false; //agent is slowing in front of the reward location 

 
module limbic_system



vis1 : [0..1] init 0;//visual input to speed gained when agent can see reward_location
vis2: [0..1] init 0;//  visual input to speed gained when agent can see reward
pos : [0..MAX] init 0;//position of agent
s : [0..10] init 0;  //state counter to help ordering of events 
speedtype : [0..2] init 0;
reward_pos: [0..MAX];

//s=1 -> precalculate uncertainties
//s=2 -> exploration
//s=3 -> has seen visual landmark, approaches
//s=4 -> at placefield, increased 5HT
//s=5 -> slowed down
//s=6 -> moving towards location of reward
//s=7 -> at end


at_reward : bool init false;
collected_reward : bool init false;
missed_reward : bool init false;

[] s=0 -> 1/7 : (reward_pos'= l + reward_spread) & (s'=1) + 1/7 : (reward_pos'= l - reward_spread) & (s'=1) + 1/7 : (reward_pos'= l) & (s'=1) + 1/7 : (reward_pos'= l + 2*reward_spread) & (s'=1) + 1/7 : (reward_pos'= l - 2*reward_spread) & (s'=1) + 1/7 : (reward_pos'= l + 3*reward_spread) & (s'=1) + 1/7 : (reward_pos'= l - 3*reward_spread) & (s'=1); 
[] s=1 -> 1/3 : (speedtype' = 0) & (s'=1) + 1/3 : (speedtype' = 1) & (s'=2)  + 1/3 : (speedtype' = 2) & (s'=2);
[] s=2 -> (vis1'=1) & (s'=3); // see area containing reward and end exploration
[] s=3 -> 1 : (s'=4); //move towards reward
[] s=4 -> 1 : (s'=5) & (in_front_of_reward_location'=true) & (pos' = wait_at_reward_location); //slow down if front of reward_location, expected to contain reward// "timed" syncronises agent movement with the counters controlling the spawning and despawning of the reward

// "timed" syncronises agent movement with the counters controlling the spawning and despawning of the reward
[timed] s=5 & speedtype=0 & pos<reward_pos-200 -> (pos' = pos+speed);
[timed] s=5 & speedtype=1 & pos<reward_pos-200 -> (pos' = pos+speedmax);
[timed] s=5 & speedtype=2 & pos<reward_pos-200 -> (pos' = pos+speedmin);
[timed] s=5 & reward_present=true & pos<reward_pos-200  -> 1 : (vis2'=1); //agent sees reward and updates vis2
[timed] s=5 & pos>=reward_pos-200 -> 1: (s'=6); //agent reaches reward location; update state counter


[timed] s=6 & reward_present=true -> (collected_reward' = true) & (at_reward' = true) & (s'=7); //agent collects reward
[timed] s=6  & reward_present=false -> (missed_reward'=true) & (at_reward'= true) & (s'=7); //agent misses reward

[] s=7 -> 1: (s'=7);  // end state has been reached




endmodule 



module reward_spawner


c1 : [0..delay] init 0; //reward spawn delay counter


spwnd : bool init false;
despwnd : bool init false;
reward_present : bool init false;

[timed] in_front_of_reward_location=false -> 1: (c1'=0);
[timed] in_front_of_reward_location=true & spwnd=false & c1=delay -> (spwnd'=true) & (c1'=0) & (reward_present'=true); //spawn reward after "delay" steps
[timed] in_front_of_reward_location=true & spwnd=false & c1<delay-> 1: (c1'=c1+1);  //increment reward spawn counter
[timed]spwnd=true -> (spwnd'=true);

endmodule





formula x = vis1 + vis2; //speed based on visual inputs

formula speed = ((x=1)?reward_unseen_speed:(x=2)?reward_seen_speed:0);

formula speedmax = ((x=1)?reward_unseen_speed + speed_uncertainty:(x=2)?(reward_seen_speed):0);

formula speedmin = ((x=1)?reward_unseen_speed - speed_uncertainty:(x=2)?(reward_seen_speed):0);


